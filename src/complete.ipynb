{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import read_csv\n",
    "from wikipedia_crawler import get_famous_people_and_save\n",
    "from create_dataframe import merge_DataFrames_and_save\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pascal\\Documents\\FH Project\\dawr\\dawr-grisons\\src\\util.py:45: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.replace('---', pd.np.nan, inplace=True)\n",
      "c:\\Users\\Pascal\\Documents\\FH Project\\dawr\\dawr-grisons\\src\\util.py:45: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.replace('---', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Create Data if it does not exit\n",
    "get_famous_people_and_save()\n",
    "merge_DataFrames_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n) -> int:\n",
    "    if n < 2:\n",
    "        return 0\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pascal\\Documents\\FH Project\\dawr\\dawr-grisons\\src\\util.py:45: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.replace('---', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv('data', 'combined_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Gemeinde_Name  Buenzli_Rank_ranking_1  Socialising_Rank_ranking_2\n",
      "23            Tschappina               96.164215                    7.041975\n",
      "73                 Furna               94.680090                   10.399434\n",
      "25             Safiental               93.900044                    9.056225\n",
      "76  Conters im PrÃ¤ttigau               93.880634                   10.443522\n",
      "20               Flerden               93.273509                   11.450971\n",
      "..                   ...                     ...                         ...\n",
      "90             Landquart               47.609104                   48.428015\n",
      "55            Silvaplana               47.442708                    9.262102\n",
      "22                Thusis               41.596902                   23.339087\n",
      "79                  Chur               39.491647                   88.629474\n",
      "52            St. Moritz               32.450354                   22.000201\n",
      "\n",
      "[101 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Bevoelkerungsdichte_normalized_inverse'] = 1 - (df['Bevoelkerungsdichte_pro_km2'] - df['Bevoelkerungsdichte_pro_km2'].min()) / (df['Bevoelkerungsdichte_pro_km2'].max() - df['Bevoelkerungsdichte_pro_km2'].min())\n",
    "df['Auslaender_in_prozent_normalized_inverse'] = (df['Auslaender_in_prozent'].max() - df['Auslaender_in_prozent']) / (df['Auslaender_in_prozent'].max() - df['Auslaender_in_prozent'].min())\n",
    "df['Buenzli_Rank_ranking_1'] = ((0.9 * df['Bevoelkerungsdichte_normalized_inverse'] + 1.6 * df['Auslaender_in_prozent_normalized_inverse'] + 0.5 * df['Wahlbeteiligung']) / 3) * 100\n",
    "\n",
    "#x_normalized_inverse = 1 - (x - x_min) / (x_max - x_min)\n",
    "#x_normalized = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "df['Bevoelkerungsdichte_normalized'] = (df['Bevoelkerungsdichte_pro_km2'] - df['Bevoelkerungsdichte_pro_km2'].min()) / (df['Bevoelkerungsdichte_pro_km2'].max() - df['Bevoelkerungsdichte_pro_km2'].min())\n",
    "df['Einwohner_normalized'] = (df['Einwohner'] - df['Einwohner'].min()) / (df['Einwohner'].max() - df['Einwohner'].min())\n",
    "df['Socialising_Rank_ranking_2'] = ((1.4 * df['Bevoelkerungsdichte_normalized'] + 1.1 * df['Einwohner_normalized'] + 0.5 * df['No_ratio']) / 3) * 100\n",
    "\n",
    "# Sum up the famous people for all districts (2 criteria used)\n",
    "# Now calculate a ratio of famous people per capita\n",
    "\n",
    "\n",
    "\n",
    "cols_to_show = ['Gemeinde_Name', 'Buenzli_Rank_ranking_1', 'Socialising_Rank_ranking_2']\n",
    "df = df.sort_values(by='Buenzli_Rank_ranking_1', ascending=False)\n",
    "print(df[cols_to_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "Name: Famous_Person_count, dtype: float64\n",
      "0    10.0\n",
      "Name: Famous_Person_count, dtype: float64\n",
      "0    True\n",
      "Name: Famous_Person_count, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "famous_count_surses = df[df['Gemeinde_Name'] == 'Surses']['Famous_Person_count'].reset_index(drop=True)\n",
    "famous_count_vaz = df[df['Gemeinde_Name'] == 'Vaz/Obervaz']['Famous_Person_count'].reset_index(drop=True)\n",
    "\n",
    "print(famous_count_surses)\n",
    "print(famous_count_vaz)\n",
    "\n",
    "print (famous_count_vaz > famous_count_surses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking stuff\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "                   'GPA': [3.5, 3.2, 3.9, 3.6],\n",
    "                   'Test Scores': [85, 90, 95, 80],\n",
    "                   'Attendance': [90, 95, 80, 85],\n",
    "                   'Participation': [75, 80, 85, 90]})\n",
    "                   \n",
    "# normalize the factors using min-max normalization\n",
    "normalized = (df[['GPA', 'Test Scores', 'Attendance', 'Participation']] \n",
    "              - df[['GPA', 'Test Scores', 'Attendance', 'Participation']].min()) / (df[['GPA', 'Test Scores', 'Attendance', 'Participation']].max() \n",
    "                   - df[['GPA', 'Test Scores', 'Attendance', 'Participation']].min())\n",
    "\n",
    "# combine the normalized factors into a single score\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weights for each factor\n",
    "weights = {'GPA': 0.3, 'Test Scores': 0.4, 'Attendance': 0.2, 'Participation': 0.1}\n",
    "\n",
    "# multiply each column by its weight factor\n",
    "weighted = df[['GPA', 'Test Scores', 'Attendance', 'Participation']].multiply(pd.Series(weights), axis=1)\n",
    "\n",
    "# normalize the weighted factors using min-max normalization\n",
    "normalized = (weighted - weighted.min()) / (weighted.max() - weighted.min())\n",
    "\n",
    "# combine the normalized, weighted factors into a single score\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weights for each factor\n",
    "weights = {'GPA': 0.3, 'Test Scores': 0.4, 'Attendance': 0.2, 'Participation': 0.1}\n",
    "\n",
    "# define a function to calculate conditional weights\n",
    "def get_weight(value):\n",
    "    if np.isnan(value) or value == 1:\n",
    "        return 0\n",
    "    elif value in [2, 3, 5, 7]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# calculate the conditional weights for the GPA column\n",
    "conditional_weights = df['GPA'].apply(get_weight)\n",
    "\n",
    "# multiply the conditional weights by the weights for the GPA column\n",
    "weighted_gpa = df['GPA'] * conditional_weights * weights['GPA']\n",
    "\n",
    "# multiply the other columns by their weights\n",
    "weighted_others = df[['Test Scores', 'Attendance', 'Participation']] * pd.Series(weights)[['Test Scores', 'Attendance', 'Participation']]\n",
    "\n",
    "# combine the weighted factors into a single score\n",
    "total_weighted = pd.concat([weighted_gpa, weighted_others], axis=1)\n",
    "normalized = (total_weighted - total_weighted.min()) / (total_weighted.max() - total_weighted.min())\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dawr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8842fe4ff5befa1ea6f626dfd16fef49ff1b37abc431b5af37874790cde90296"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
