{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import read_csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Documents\\Programming\\dawr\\dawr-grisons\\src\\util.py:45: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.replace('---', pd.np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv('data', 'combined_data_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Gemeinde_Name  Buenzli_Rank_ranking_1\n",
      "73                 Furna               99.659885\n",
      "23            Tschappina               99.177956\n",
      "76  Conters im PrÃ¤ttigau               98.318343\n",
      "25             Safiental               98.166074\n",
      "34    Muntogna da Schons               97.907019\n",
      "..                   ...                     ...\n",
      "90             Landquart               44.706145\n",
      "55            Silvaplana               43.486438\n",
      "22                Thusis               38.233009\n",
      "79                  Chur               35.358244\n",
      "52            St. Moritz               26.329352\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Bevoelkerungsdichte_normalized_inverse'] = 1 - (df['Bevoelkerungsdichte_pro_km2'] - df['Bevoelkerungsdichte_pro_km2'].min()) / (df['Bevoelkerungsdichte_pro_km2'].max() - df['Bevoelkerungsdichte_pro_km2'].min())\n",
    "df['Auslaender_in_prozent_normalized_inverse'] = (df['Auslaender_in_prozent'].max() - df['Auslaender_in_prozent']) / (df['Auslaender_in_prozent'].max() - df['Auslaender_in_prozent'].min())\n",
    "df['Buenzli_Rank_ranking_1'] = ((0.7 * df['Bevoelkerungsdichte_normalized_inverse'] + 1.3 * df['Auslaender_in_prozent_normalized_inverse']) / 2) * 100\n",
    "\n",
    "df['Bevoelkerungsdichte_normalized']\n",
    "df['Einwohner_normalized']\n",
    "df['Twenty_to_Sixtyfour_normalized']\n",
    "\n",
    "cols_to_show = ['Gemeinde_Name', 'Buenzli_Rank_ranking_1']\n",
    "df = df.sort_values(by='Buenzli_Rank_ranking_1', ascending=False)\n",
    "print(df[cols_to_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "Name: Famous_Person_count, dtype: float64\n",
      "0    10.0\n",
      "Name: Famous_Person_count, dtype: float64\n",
      "0    True\n",
      "Name: Famous_Person_count, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "famous_count_surses = df[df['Gemeinde_Name'] == 'Surses']['Famous_Person_count'].reset_index(drop=True)\n",
    "famous_count_vaz = df[df['Gemeinde_Name'] == 'Vaz/Obervaz']['Famous_Person_count'].reset_index(drop=True)\n",
    "\n",
    "print(famous_count_surses)\n",
    "print(famous_count_vaz)\n",
    "\n",
    "print (famous_count_vaz > famous_count_surses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking stuff\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "                   'GPA': [3.5, 3.2, 3.9, 3.6],\n",
    "                   'Test Scores': [85, 90, 95, 80],\n",
    "                   'Attendance': [90, 95, 80, 85],\n",
    "                   'Participation': [75, 80, 85, 90]})\n",
    "                   \n",
    "# normalize the factors using min-max normalization\n",
    "normalized = (df[['GPA', 'Test Scores', 'Attendance', 'Participation']] \n",
    "              - df[['GPA', 'Test Scores', 'Attendance', 'Participation']].min()) / (df[['GPA', 'Test Scores', 'Attendance', 'Participation']].max() \n",
    "                   - df[['GPA', 'Test Scores', 'Attendance', 'Participation']].min())\n",
    "\n",
    "# combine the normalized factors into a single score\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weights for each factor\n",
    "weights = {'GPA': 0.3, 'Test Scores': 0.4, 'Attendance': 0.2, 'Participation': 0.1}\n",
    "\n",
    "# multiply each column by its weight factor\n",
    "weighted = df[['GPA', 'Test Scores', 'Attendance', 'Participation']].multiply(pd.Series(weights), axis=1)\n",
    "\n",
    "# normalize the weighted factors using min-max normalization\n",
    "normalized = (weighted - weighted.min()) / (weighted.max() - weighted.min())\n",
    "\n",
    "# combine the normalized, weighted factors into a single score\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the weights for each factor\n",
    "weights = {'GPA': 0.3, 'Test Scores': 0.4, 'Attendance': 0.2, 'Participation': 0.1}\n",
    "\n",
    "# define a function to calculate conditional weights\n",
    "def get_weight(value):\n",
    "    if np.isnan(value) or value == 1:\n",
    "        return 0\n",
    "    elif value in [2, 3, 5, 7]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# calculate the conditional weights for the GPA column\n",
    "conditional_weights = df['GPA'].apply(get_weight)\n",
    "\n",
    "# multiply the conditional weights by the weights for the GPA column\n",
    "weighted_gpa = df['GPA'] * conditional_weights * weights['GPA']\n",
    "\n",
    "# multiply the other columns by their weights\n",
    "weighted_others = df[['Test Scores', 'Attendance', 'Participation']] * pd.Series(weights)[['Test Scores', 'Attendance', 'Participation']]\n",
    "\n",
    "# combine the weighted factors into a single score\n",
    "total_weighted = pd.concat([weighted_gpa, weighted_others], axis=1)\n",
    "normalized = (total_weighted - total_weighted.min()) / (total_weighted.max() - total_weighted.min())\n",
    "df['Ranking Score'] = normalized.mean(axis=1) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dawr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8842fe4ff5befa1ea6f626dfd16fef49ff1b37abc431b5af37874790cde90296"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
